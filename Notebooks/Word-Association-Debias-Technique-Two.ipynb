{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Gender Bias in Autocomplete AI\n","\n","The AI at hand is to predict next words based on what users have typed. It's pretty much how autocomplete in Google search works. Let's try to make the autocomplete algorithm less biased toward a certain gender.\n","\n","The code learns from an existing corpora (text-based dataset), and performs autocomplete when receiving a word input by a user."],"metadata":{"id":"N_aoMOoKl-BJ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Ecd0J7pBl_bo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa06ec9c-dade-4859-d9c9-eac16fd26cc3","executionInfo":{"status":"ok","timestamp":1689973834296,"user_tz":240,"elapsed":22082,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords"],"metadata":{"id":"J2yTT_YJmBlE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e92b2bf9-537c-45fa-8f37-51bd0ee5f40b","executionInfo":{"status":"ok","timestamp":1689973840493,"user_tz":240,"elapsed":6198,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('averaged_perceptron_tagger')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBklY1yorL_H","executionInfo":{"status":"ok","timestamp":1689973840664,"user_tz":240,"elapsed":173,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}},"outputId":"005f86bb-7f4c-4147-c6ba-8b45817fe901"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import pandas as pd\n","import collections"],"metadata":{"id":"WyCq42kpqAFX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training with Bias"],"metadata":{"id":"2ZjtYs3efa-E"}},{"cell_type":"code","source":["def preprocess(text):\n","    tokens = word_tokenize(text.lower())\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n","    return tokens\n","\n","dataset = pd.read_csv(\"/content/drive/My Drive/Autocomplete/Autocomplete Dataset.csv\")\n","dataset[\"Comments\"] = dataset[\"Comments\"].str.replace('\\r\\n', '')\n","text_list = dataset[\"Comments\"].tolist()\n","text = ' '.join(text_list)\n","\n","# Preprocess the text\n","tokens = preprocess(text)\n","\n","# larger range\n","def train_model(tokens):\n","    model = collections.defaultdict(list)\n","    for i in range(len(tokens)-1):\n","        key = tokens[i]\n","        values = tokens[i-2:i] + tokens[i+1:i+3]\n","        model[key].extend(values)\n","    return model\n","\n","# Train the model\n","model = train_model(tokens)\n","\n","import random\n","\n","def generate_prediction(model, prefix):\n","    if prefix in model:\n","        suffixes = model[prefix]\n","        return random.choice(suffixes)\n","    else:\n","        return None\n","\n","def check_adjective(word):\n","    tagged_word = nltk.pos_tag([word])\n","    pos = tagged_word[0][1]\n","    return pos.startswith('JJ')\n","\n","# Take input from user\n","input_str = input(\"Enter word: \")\n","output_num = input(\"How many words do you want to generate: \")\n","\n","# Preprocess the input\n","input_tokens = preprocess(input_str)\n","\n","# Generate prediction\n","count = 0\n","while count < int(output_num):\n","    new_word = generate_prediction(model, input_tokens[-1])\n","    if new_word != \"women\" and new_word != \"men\" and check_adjective(new_word):\n","      count += 1\n","      input_tokens.append(new_word)\n","\n","# Print the prediction\n","if input_tokens:\n","    print(\"Next word prediction:\", input_tokens[1:])\n","else:\n","    print(\"No prediction found.\")"],"metadata":{"id":"9kUWpyYgmBnT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f700411e-aaed-43bd-c6c5-727326b14327","executionInfo":{"status":"ok","timestamp":1689974171799,"user_tz":240,"elapsed":3156,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter word: women\n","How many words do you want to generate: 5\n","Next word prediction: ['empathetic', 'sensitive', 'empathetic', 'sensitive', 'empathetic']\n"]}]},{"cell_type":"markdown","source":["### Improve the Model"],"metadata":{"id":"2m60pe_r_r3u"}},{"cell_type":"markdown","source":["Let's inspect the transition matrix of our model and modify the model to make the probability of predicting biased words smaller."],"metadata":{"id":"o2DKmSmW_utR"}},{"cell_type":"code","source":["import sklearn\n","from collections import Counter"],"metadata":{"id":"PIinrIguKAN-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_transition_matrix(model):\n","  for key, entry in model.items():\n","    model[key] = Counter(entry)\n","  transition_matrix = pd.DataFrame(model).fillna(0)\n","  tm_normalized = transition_matrix.div(transition_matrix.sum(axis=1), axis=0)\n","  return tm_normalized"],"metadata":{"id":"3ZFZis6BJLQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transition_matrix = create_transition_matrix(model)"],"metadata":{"id":"XiFLjL1PS1kH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transition_probability_for_women = {k: v[0] for k, v in sorted(transition_matrix.loc[[\"women\"]].to_dict(orient='list').items(), key=lambda item: item[1], reverse=True)}"],"metadata":{"id":"8lywx4ayYvZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list(transition_probability_for_women.items())[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2Fug7MNWya4","executionInfo":{"status":"ok","timestamp":1689976437605,"user_tz":240,"elapsed":132,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}},"outputId":"e6921a8c-11b8-42f4-ddef-de8fa282b289"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('men', 0.030927835051546393),\n"," ('better', 0.030927835051546393),\n"," ('prioritize', 0.030927835051546393),\n"," ('inclined', 0.030927835051546393),\n"," ('towards', 0.030927835051546393),\n"," ('likely', 0.030927835051546393),\n"," ('caring', 0.020618556701030927),\n"," ('emotional', 0.020618556701030927),\n"," ('multitasking', 0.020618556701030927),\n"," ('natural', 0.020618556701030927)]"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","source":["Now you can try manually changing the probability of some biased words to make it less likely to appear in the autocomplete results when you input \"women\". However, make the sure the transition probability to all the words sum up to 1."],"metadata":{"id":"2SmA8MF6ZtZV"}},{"cell_type":"code","source":["biased_word = [input(\"What words do you think are biased? \" )]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0oSgGyJ4Z5D_","executionInfo":{"status":"ok","timestamp":1689976232868,"user_tz":240,"elapsed":7454,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}},"outputId":"8caa8906-9c27-4bef-8fef-f0ddef4c0f88"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["What words do you think are biased?emotional, caring\n"]}]},{"cell_type":"code","source":["penalty_factor = float(input(\"How much do you want to discount the biased words? Please enter a number between 0 and 1 \" ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ciovXHLb03l","executionInfo":{"status":"ok","timestamp":1689976367578,"user_tz":240,"elapsed":2947,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}},"outputId":"5582008a-356d-4eee-c238-d2b5df105cbb"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["How much do you want to discount the biased words? Please enter a number between 0 and 1  0.5\n"]}]},{"cell_type":"code","source":["def bias_fine_tune(biased_word,penalty_factor, transition_probability, key):\n","  for key, prob in transition_probability.items():\n","    if key in biased_word:\n","      transition_probability[key] *= penalty_factor\n","  transition_matrix.loc[key] = transition_probability\n","  transition_matrix_normalized = transition_matrix.div(transition_matrix.sum(axis=1), axis=0)\n","  return transition_matrix_normalized"],"metadata":{"id":"z0bIWMRBctUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["debiased_transition_matrix = bias_fine_tune(biased_word,penalty_factor,transition_probability_for_women, \"women\");"],"metadata":{"id":"cYYB-gIQcT33"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can use the new transition matrix to make the predictions. Let's see if there's any difference in the results."],"metadata":{"id":"vI_-f2XBdvJz"}},{"cell_type":"code","source":["def generate_prediction_with_transition_matrix(model, prefix, number):\n","    count = 0\n","    predicted_words = []\n","    if prefix in transition_matrix.index:\n","      while count < int(number):\n","        possible_words = list(transition_matrix.columns)\n","        probabilities = list(transition_matrix.loc[prefix])\n","        new_word = random.choices(possible_words, weights=probabilities, k=1)[0]\n","        if new_word != \"women\" and new_word != \"men\" and check_adjective(new_word):\n","          count += 1\n","          predicted_words.append(new_word)\n","      return predicted_words\n","    else:\n","        return None"],"metadata":{"id":"JkczsUCqfK6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_str = input(\"Enter word: \")\n","output_num = input(\"How many words do you want to generate: \")\n","generate_prediction_with_transition_matrix(debiased_transition_matrix,input_str,output_num)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wx8felc9d4s8","executionInfo":{"status":"ok","timestamp":1689977919533,"user_tz":240,"elapsed":6781,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}},"outputId":"8797d0a8-a5a7-482a-8137-7ed3a15e37e2"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter word: women\n","How many words do you want to generate: 5\n"]},{"output_type":"execute_result","data":{"text/plain":["['inclined', 'empathetic', 'emotional', 'empathetic', 'organizational']"]},"metadata":{},"execution_count":112}]},{"cell_type":"markdown","source":["Now do the same thing for the word transition probability for men."],"metadata":{"id":"mm2kvU3LiVSM"}},{"cell_type":"code","source":["transition_probability_for_men = {k: v[0] for k, v in sorted(transition_matrix.loc[[\"men\"]].to_dict(orient='list').items(), key=lambda item: item[1], reverse=True)}\n","list(transition_probability_for_men.items())[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JXpgWzpidJL","executionInfo":{"status":"ok","timestamp":1689978016208,"user_tz":240,"elapsed":167,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}},"outputId":"07563b3d-36a1-420e-cf2c-dc2d46bba0c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('less', 0.07142857142857142),\n"," ('emotional', 0.03571428571428571),\n"," ('inclined', 0.03571428571428571),\n"," ('women', 0.026785714285714284),\n"," ('nurturing', 0.026785714285714284),\n"," ('confident', 0.026785714285714284),\n"," ('focused', 0.026785714285714284),\n"," ('interested', 0.026785714285714284),\n"," ('natural', 0.017857142857142856),\n"," ('assertive', 0.017857142857142856)]"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["biased_word = [input(\"What words do you think are biased? \" )]\n","penalty_factor = float(input(\"How much do you want to discount the biased words? Please enter a number between 0 and 1 \" ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUUhGYOvilPE","executionInfo":{"status":"ok","timestamp":1689978074411,"user_tz":240,"elapsed":7967,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}},"outputId":"4d71dcbb-48ce-48ee-abc4-161f80d28631"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["What words do you think are biased? confident\n","How much do you want to discount the biased words? Please enter a number between 0 and 1 0.5\n"]}]},{"cell_type":"code","source":["debiased_transition_matrix = bias_fine_tune(biased_word,penalty_factor,transition_probability_for_men, \"men\");"],"metadata":{"id":"liK7eujEiqAE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_str = input(\"Enter word: \")\n","output_num = input(\"How many words do you want to generate: \")\n","generate_prediction_with_transition_matrix(debiased_transition_matrix,input_str,output_num)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEzv5K6Mish8","executionInfo":{"status":"ok","timestamp":1689978198748,"user_tz":240,"elapsed":4275,"user":{"displayName":"AIGenderBiasEducation","userId":"03024860783463489198"}},"outputId":"e1d17619-7739-44b1-ecb0-129f80d7e1c5"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter word: men\n","How many words do you want to generate: 5\n"]},{"output_type":"execute_result","data":{"text/plain":["['emotional', 'inclined', 'potential', 'interpersonal', 'potential']"]},"metadata":{},"execution_count":120}]}]}